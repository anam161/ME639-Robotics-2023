# -*- coding: utf-8 -*-
"""Untitled68.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vbF1uT8drE7KCAuYe2KDemBLbTVehqwE
"""

import numpy as np
import time
from leap_hand_utils.dynamixel_client import *
import leap_hand_utils.leap_hand_utils as lhu
import cv2
import cv2.aruco as aruco

# Pose Estimation Setup
camera_matrix = np.array([[542.72140565, 0, 307.76862441],
                          [0, 564.13186784, 224.63433001],
                          [0, 0, 1]])
dist_coeffs = np.array([-0.08048309, 0.59678798, -0.01890385, -0.02925722, -1.08808723])
cap = cv2.VideoCapture(0)
aruco_dict = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)
parameters = aruco.DetectorParameters_create()

def draw_axis(frame, camera_matrix, dist_coeffs, rvec, tvec, length=0.1):
    axis = np.float32([[length,0,0], [0,length,0], [0,0,-length], [0,0,0]]).reshape(-1,3)
    imgpts, _ = cv2.projectPoints(axis, rvec, tvec, camera_matrix, dist_coeffs)
    corner = tuple(map(int, imgpts[3].ravel()))
    pt1 = tuple(map(int, imgpts[0].ravel()))
    pt2 = tuple(map(int, imgpts[1].ravel()))
    pt3 = tuple(map(int, imgpts[2].ravel()))

    frame = cv2.line(frame, corner, pt1, (255,0,0), 5)  # X-axis in red
    frame = cv2.line(frame, corner, pt2, (0,255,0), 5)  # Y-axis in green
    frame = cv2.line(frame, corner, pt3, (0,0,255), 5)  # Z-axis in blue
    return frame

def calculate_relative_pose(rvec1, tvec1, rvec2, tvec2):
    R1, _ = cv2.Rodrigues(rvec1)
    R2, _ = cv2.Rodrigues(rvec2)
    tvec1 = tvec1.reshape(3, 1)
    tvec2 = tvec2.reshape(3, 1)
    t_relative = tvec2 - tvec1
    t_relative[2] -= 0.24  # Adjust as needed
    R_relative = R2 @ R1.T
    r_relative, _ = cv2.Rodrigues(R_relative)
    return r_relative, t_relative

def draw_origin_and_object_axes(frame, camera_matrix, dist_coeffs, rvec_object, tvec_object):
    origin_rvec = np.array([0, 0, 0], dtype=np.float32)
    origin_tvec = np.array([0, 0, 0], dtype=np.float32)
    rvec_object_zero = np.array([0, 0, 0], dtype=np.float32)
    frame = draw_axis(frame, camera_matrix, dist_coeffs, origin_rvec, origin_tvec, 0.1)
    frame = draw_axis(frame, camera_matrix, dist_coeffs, rvec_object_zero, tvec_object, 0.1)
    rvec_relative, tvec_relative = calculate_relative_pose(origin_rvec, origin_tvec, rvec_object_zero, tvec_object)
    object_pose = np.hstack((tvec_relative.ravel(), np.zeros(3)))  # Orientation is forced to zero
    return frame, object_pose

# Object Impedance Control Setup
def force_vec(s, t, n):
    return np.column_stack([s, t, n])

s1, t1, n1 = np.array([0, 1, 0]), np.array([0, 0, 1]), np.array([1, 0, 0])
s2, t2, n2 = np.array([0, 1, 0]), np.array([0, 0, -1]), np.array([-1, 0, 0])
z1, z2 = force_vec(s1, t1, n1), force_vec(s2, t2, n2)

def cross_prod(x, vec):
    return np.cross(x, vec)

x1, x2 = np.array([-0.03, 0, 0]), np.array([0.03, 0, 0])
p1, q1, r1 = cross_prod(x1, s1), cross_prod(x1, t1), cross_prod(x1, n1)
p2, q2, r2 = cross_prod(x2, s2), cross_prod(x2, t2), cross_prod(x2, n2)
k, l = np.column_stack([p1, q1, r1]), np.column_stack([p2, q2, r2])
G1, G2 = np.concatenate([z1, k]), np.concatenate([z2, l])
G = np.block([G1, G2])

def W(s, t, n):
    return np.hstack([np.array(s).reshape(3, 1), np.array(t).reshape(3, 1), np.array(n).reshape(3, 1)])

def rotation_matrix_3d(theta):
    return np.array([[np.cos(theta), -np.sin(theta), 0],
                     [np.sin(theta), np.cos(theta), 0],
                     [0, 0, 1]])

def jacobian(l1, l2, l3, theta1, theta2, theta3):
    return np.array([
        [-l1*np.sin(theta1) - l2*np.sin(theta1+theta2) - l3*np.sin(theta1+theta2+theta3),
         -l2*np.sin(theta1+theta2) - l3*np.sin(theta1+theta2+theta3),
         -l3*np.sin(theta1+theta2+theta3)],
        [l1*np.cos(theta1) + l2*np.cos(theta1+theta2) + l3*np.cos(theta1+theta2+theta3),
         l2*np.cos(theta1+theta2) + l3*np.cos(theta1+theta2+theta3),
         l3*np.cos(theta1+theta2+theta3)],
        [0, 0, 0]
    ])

def hand_jacobian(s, t, n, w, R, J):
    return np.dot(np.dot(w.T, R), J)

l1_f1, l2_f1, l3_f1 = 0.05, 0.035, 0.05
theta1_f1, theta2_f1, theta3_f1 = 0.942, 0.44, 0.22
w1, R1 = W(s1, t1, n1), rotation_matrix_3d(0)
J1 = jacobian(l1_f1, l2_f1, l3_f1, theta1_f1, theta2_f1, theta3_f1)
HJR1 = hand_jacobian(s1, t1, n1, w1, R1, J1)

l1_f2, l2_f2, l3_f2 = 0.05, 0.035, 0.05
theta1_f2, theta2_f2, theta3_f2 = 1.54, 0.251, 0.0942
w2, R2 = W(s2, t2, n2), rotation_matrix_3d(0)
J2 = jacobian(l1_f2, l2_f2, l3_f2, theta1_f2, theta2_f2, theta3_f2)
HJR2 = hand_jacobian(s2, t2, n2, w2, R2, J2)

O = np.zeros((3, 3))
HJR1_full, HJR2_full = np.concatenate([HJR1, O], axis=1), np.concatenate([O, HJR2], axis=1)
Hand_jacobian = np.concatenate([HJR1_full, HJR2_full], axis=0)
Jh = Hand_jacobian

G_pinv = np.linalg.pinv(G)
Xd = np.array([0, 0, 0, 0, 0, 0])
Kp = np.diag([10]*6)
N = np.array([0.4]*6)

# Hardware control code
class LeapNode:
    def __init__(self):
        self.torque_lower = -1023
        self.torque_upper = 1023
        self.kP = 500
        self.kI = 0
        self.kD = 300
        self.curr_lim = 350
        self.motor_directions = np.array([-1]*16)
        self.motors = list(range(16))
        self.num_motors = len(self.motors)
        try:
            self.dxl_client = DynamixelClient(self.motors, '/dev/ttyUSB0', 4000000)
            self.dxl_client.set_motor_directions(self.motor_directions)
        except:
            print("Warning: Could not connect to Dynamixel servos.")
            self.dxl_client = None

    def send_torque_cmd(self, desired_torque):
        if self.dxl_client is not None:
            torque_cmd = np.clip(desired_torque, self.torque_lower, self.torque_upper)
            try:
                self.dxl_client.send_torque_cmd(self.motors, torque_cmd.astype(int))
            except Exception as e:
                print(f"Warning: Failed to send torque command: {e}")

# Control loop with pose integration
def control_loop(node, Kp, N):
    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, aruco_dict, parameters=parameters)

        if ids is not None and len(ids) == 2:
            idx_marker_0, idx_marker_1 = np.where(ids == 0)[0][0], np.where(ids == 1)[0][0]
            rvec_0, tvec_0 = aruco.estimatePoseSingleMarkers(corners[idx_marker_0], 0.06, camera_matrix, dist_coeffs)[0:2]
            rvec_1, tvec_1 = aruco.estimatePoseSingleMarkers(corners[idx_marker_1], 0.06, camera_matrix, dist_coeffs)[0:2]

            tvec_0, tvec_1 = tvec_0.reshape(-1), tvec_1.reshape(-1)
            rvec_0, rvec_1 = rvec_0.reshape(-1), rvec_1.reshape(-1)
            frame, object_pose = draw_origin_and_object_axes(frame, camera_matrix, dist_coeffs, rvec_1, tvec_1)

            X = object_pose
            error = Xd - X
            tau_ext = np.dot(Kp, error) + N

            torque_cmd = np.dot(G_pinv.T, tau_ext)
            node.send_torque_cmd(torque_cmd)

        cv2.imshow('Pose Estimation', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

# Main entry point
if __name__ == "__main__":
    leap_node = LeapNode()
    control_loop(leap_node, Kp, N)